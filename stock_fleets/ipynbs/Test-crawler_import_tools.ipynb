{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(\"..\")\n",
    "import django\n",
    "django.setup()\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from dateutil.rrule import rrule, DAILY, MONTHLY\n",
    "import time\n",
    "from django.core.exceptions import ObjectDoesNotExist\n",
    "from crawlers.models import *\n",
    "\n",
    "#pycharm 測試\n",
    "from crawlers.finlab.crawler_pioneers import *\n",
    "from crawlers.finlab.crawler_import_tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=CrawlerProcess(crawl_stock_price_tw,StockPriceTW,'date_range')\n",
    "print(D)\n",
    "D.auto_update_crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benbilly3/opt/anaconda3/lib/python3.7/site-packages/pymysql/cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawlers_monthlyrevenuetw table_latest_date:2020-04-10 00:00:00\n",
      "https://mops.twse.com.tw/nas/t21/sii/t21sc03_109_3.html\n",
      "https://mops.twse.com.tw/nas/t21/otc/t21sc03_109_3.html\n",
      "https://mops.twse.com.tw/nas/t21/rotc/t21sc03_109_3.html\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:1560 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:3708 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:4968 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:6289 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:3030 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:1438 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:1435 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:1586 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:4147 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:6492 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:3228 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:6510 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:3625 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:3630 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:5315 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:2241 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:6617 Date:2020-04-10 00:00:00\n",
      "update <class 'crawlers.models.MonthlyRevenueTW'> Stock_id:6634 Date:2020-04-10 00:00:00\n",
      "Finish <class 'crawlers.models.MonthlyRevenueTW'>bulk_create:0\n",
      "Finish <class 'crawlers.models.MonthlyRevenueTW'>bulk_update:18\n",
      "Finish 2020-04-10 Data\n",
      "https://mops.twse.com.tw/nas/t21/sii/t21sc03_109_4.html\n",
      "html5lib not found, please install it\n",
      "**WARRN: Pandas cannot find any table in the HTML file\n",
      "fail, check if 2020-05-10 is a holiday\n"
     ]
    }
   ],
   "source": [
    "M=CrawlerProcess(crawl_monthly_revenue_tw  ,MonthlyRevenueTW,'month_range')\n",
    "print(M)\n",
    "M.auto_update_crawl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk 功能批次匯入資料庫測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢查日期\n",
    "\n",
    "加快寫入速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_info = 'mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8'.format(\"root\",\"benbilly3@\",\"localhost\",3306,\"finlab_django\")\n",
    "engine = create_engine(connect_info)\n",
    "\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    return [dt.date() for dt in rrule(DAILY, dtstart=start_date, until=end_date)]\n",
    "\n",
    "\n",
    "def month_range(start_date, end_date):\n",
    "    return [dt.date() for dt in rrule(MONTHLY, dtstart=start_date, until=end_date)]\n",
    "\n",
    "\n",
    "def season_range(start_date, end_date):\n",
    "    if isinstance(start_date, datetime.datetime):\n",
    "        start_date = start_date.date()\n",
    "\n",
    "    if isinstance(end_date, datetime.datetime):\n",
    "        end_date = end_date.date()\n",
    "\n",
    "    ret = []\n",
    "    for year in range(start_date.year - 1, end_date.year + 1):\n",
    "        ret += [datetime.date(year, 5, 15),\n",
    "                datetime.date(year, 8, 14),\n",
    "                datetime.date(year, 11, 14),\n",
    "                datetime.date(year + 1, 3, 31)]\n",
    "    ret = [r for r in ret if start_date < r < end_date]\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def table_exist(conn, table):\n",
    "    return list(conn.execute(\n",
    "        \"select count(*) from information_schema.tables where TABLE_NAME=\" + \"'\" + table + \"'\"))[0][0] == 1\n",
    "\n",
    "\n",
    "def table_latest_date(conn, table):\n",
    "    try:\n",
    "        cursor = list(conn.execute('SELECT date FROM ' + table + ' ORDER BY date DESC LIMIT 1;'))\n",
    "        return cursor[0][0]\n",
    "    except IndexError:\n",
    "        return print(\"No Data\")\n",
    "\n",
    "\n",
    "def table_earliest_date(conn, table):\n",
    "    try:\n",
    "        cursor = list(conn.execute('SELECT date FROM ' + table + ' ORDER BY date ASC LIMIT 1;'))\n",
    "        return cursor[0][0]\n",
    "    except IndexError:\n",
    "        return print(\"No Data\")\n",
    "\n",
    "\n",
    "def in_date_list(conn, model_name,check_date):\n",
    "    table=model_name._meta.db_table\n",
    "    cursor = list(conn.execute(\"SELECT date FROM \"+table+\" where date ='\"+check_date+\"'\"))\n",
    "    if len(cursor)>0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# table=StockPriceTW._meta.db_table\n",
    "# date='2020-03-31'\n",
    "# a=\"SELECT date FROM \"+table+\" where date ='\"+date+\"'\"\n",
    "# cursor = list(engine.execute(a))\n",
    "# len(cursor)\n",
    "# y=in_date_list(engine, StockPriceTW,'2005-2-14')\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  匯入資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_to_sql(model_name, df):\n",
    "\n",
    "    bulk_update_data=[]\n",
    "    bulk_create_data=[] \n",
    "    \n",
    "    # if data_date isn't in table,process bulk_create\n",
    "    data_date=df['date'].iloc[0].strftime('%Y-%m-%d')\n",
    "    check_date=in_date_list(engine,model_name,data_date)\n",
    "    \n",
    "    if check_date == False:\n",
    "    # Change CSV to iterrow\n",
    "        for index, item in df.iterrows():\n",
    "            # Use bulk_update to update obj,PS:must include primekey column\n",
    "            try:\n",
    "                obj_create_data = dict((field.name,item[field.name]) for field in model_name._meta.fields if\n",
    "                                    field.name != 'id')\n",
    "                obj_create=model_name(**obj_create_data)\n",
    "                bulk_create_data.append(obj_create)            \n",
    "                print(f\"create{' '}{model_name}{' '}Stock_id:{item['stock_id']}{' '}Date:{item['date']}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"error{' '}{e}{' '}Stock_id:{item['stock_id']}{' '}Date:{item['date']}\")\n",
    "                pass            \n",
    " \n",
    "\n",
    "    else:\n",
    "        # Change CSV to iterrow\n",
    "        for index, item in df.iterrows():\n",
    "\n",
    "            # Use bulk_update to update obj,PS:must include primekey column\n",
    "            try:\n",
    "                obj_check = model_name.objects.get(stock_id=item['stock_id'], date=item['date'])\n",
    "                obj_update_data = list((field.name,item[field.name]) if field.name !='id' else (field.name,obj_check.id) for field in model_name._meta.fields)\n",
    "\n",
    "                for attributes,update_value in obj_update_data:\n",
    "                    obj_check.attribute=update_value\n",
    "\n",
    "                bulk_update_data.append(obj_check)\n",
    "                print(f\"update{' '}{model_name}{' '}Stock_id:{item['stock_id']}{' '}Date:{item['date']}\")\n",
    "\n",
    "            # Use dict to bulk_create obj when get nothing ,process incomplete data\n",
    "            except ObjectDoesNotExist:\n",
    "                obj_create_data = dict((field.name,item[field.name]) for field in model_name._meta.fields if\n",
    "                                    field.name != 'id')\n",
    "                obj_create=model_name(**obj_create_data)\n",
    "                bulk_create_data.append(obj_create)            \n",
    "                print(f\"create{' '}{model_name}{' '}Stock_id:{item['stock_id']}{' '}Date:{item['date']}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"error{' '}{e}{' '}Stock_id:{item['stock_id']}{' '}Date:{item['date']}\")\n",
    "                pass\n",
    "    \n",
    "    # Process bulk\n",
    "    model_name.objects.bulk_create(bulk_create_data, batch_size=1000)\n",
    "    print(f\"Finish{' '}{model_name}{'bulk_create'}{':'}{len(bulk_create_data)}\")\n",
    "    update_fields_area= [field.name for field in model_name._meta.fields if field.name !='id']\n",
    "    model_name.objects.bulk_update(bulk_update_data,update_fields_area, batch_size=1000)\n",
    "    print(f\"Finish{' '}{model_name}{'bulk_update'}{':'}{len(bulk_update_data)}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   爬蟲執行前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlerProcess:\n",
    "\n",
    "    def __init__(self, func, model_name, range_date):\n",
    "        self.crawler_func_name = func\n",
    "        self.model_name = model_name\n",
    "        self.table_latest_date = table_latest_date(engine, self.model_name._meta.db_table)\n",
    "        self.range_date = range_date\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.model_name._meta.db_table) + ' ' + \"table_latest_date:\" + str(self.table_latest_date)\n",
    "\n",
    "    def crawl_process(self, date_list: list):\n",
    "\n",
    "        for d in date_list:\n",
    "            df = self.crawler_func_name(d)\n",
    "            try:\n",
    "                ret = df.drop_duplicates(['stock_id', 'date'], keep='last')\n",
    "                add_to_sql(self.model_name, ret)\n",
    "                print(f'Finish {d} Data')\n",
    "\n",
    "            # holiday is blank\n",
    "            except AttributeError:\n",
    "                print(f'fail, check if {d} is a holiday')\n",
    "            time.sleep(12)\n",
    "\n",
    "    # 指定區間，主要為測試用\n",
    "    def specified_date_crawl(self, start_date: str, end_date: str):\n",
    "\n",
    "        start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "        try:\n",
    "            if (start_date - end_date).days <= 0:\n",
    "                if self.range_date == 'date_range':\n",
    "                    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "                    date_list = date_range(start_date, end_date)[1:]\n",
    "                elif self.range_date == 'month_range':\n",
    "                    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\") + datetime.timedelta(days=45)\n",
    "                    date_list = month_range(start_date, end_date)\n",
    "                    date_list = date_list\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "                self.crawl_process(date_list)\n",
    "            else:\n",
    "                print(f\"The start_date > your end_date,please modify your start_date <={end_date} .\")\n",
    "\n",
    "        except ValueError:\n",
    "            print('Error:last_day form is %Y-%m-%d,please modify. ')\n",
    "            return None\n",
    "\n",
    "    # 進度判斷\n",
    "    def working_process(self):\n",
    "        recent = datetime.datetime.now()\n",
    "        day_num = (recent - self.table_latest_date).days\n",
    "        if self.range_date == 'date_range':\n",
    "            if day_num > 0:\n",
    "                return 0\n",
    "            elif day_num == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "\n",
    "        elif self.range_date == 'month_range':\n",
    "            return 0\n",
    "\n",
    "    # 自動爬取結尾後日期的資料\n",
    "    def auto_update_crawl(self, last_day='Now'):\n",
    "\n",
    "        try:\n",
    "            if last_day == 'Now':\n",
    "                end_date = datetime.datetime.now() + datetime.timedelta(days=45)\n",
    "            else:\n",
    "                end_date = datetime.datetime.strptime(last_day, \"%Y-%m-%d\") + datetime.timedelta(days=45)\n",
    "\n",
    "            if self.working_process() == 0:\n",
    "                start_date = self.table_latest_date\n",
    "                if self.range_date == 'date_range':\n",
    "                    # [1:] avoid same index,let program be faster\n",
    "                    date_list = date_range(start_date, end_date)[1:]\n",
    "                elif self.range_date == 'month_range':\n",
    "                    date_list = month_range(start_date, end_date)\n",
    "                else:\n",
    "                    date_list = season_range(start_date, end_date)\n",
    "                self.crawl_process(date_list)\n",
    "\n",
    "            elif self.working_process() == 1:\n",
    "                print(f\"Finish Update Work\")\n",
    "                return None\n",
    "            else:\n",
    "                print(f\"The table_latest_date > your setting date,please modify your setting date >{last_day} .\")\n",
    "                return None\n",
    "\n",
    "        except ValueError:\n",
    "            print('Error:last_day form is %Y-%m-%d,please modify. ')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬蟲執行檔Class測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  爬蟲測試範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_stock_price_tw(date):\n",
    "    \n",
    "    # 上市爬蟲,將 date 變成字串 舉例：'20180525' \n",
    "    datestr = date.strftime('%Y%m%d')\n",
    "    \n",
    "    # 從網站上依照 datestr 將指定日期的股價抓下來\n",
    "    r = requests.post('http://www.twse.com.tw/exchangeReport/MI_INDEX?response=csv&date=' + datestr + '&type=ALLBUT0999')\n",
    "    \n",
    "    # 將抓下來的資料（r.text），其中的等號給刪除\n",
    "    content = r.text.replace('=', '')\n",
    "    \n",
    "    # 將 column 數量小於等於 10 的行數都刪除\n",
    "    lines = content.split('\\n')\n",
    "    lines = list(filter(lambda l:len(l.split('\",')) > 10, lines))\n",
    "    \n",
    "    # 將每一行再合成同一行，並用肉眼看不到的換行符號'\\n'分開\n",
    "    content = \"\\n\".join(lines)\n",
    "    \n",
    "    # 假如沒下載到，則回傳None（代表抓不到資料）\n",
    "    if content == '':\n",
    "        return None\n",
    "    \n",
    "    # 將content變成檔案：StringIO，並且用pd.read_csv將表格讀取進來\n",
    "    df = pd.read_csv(StringIO(content))\n",
    "      \n",
    "    \n",
    "    # 將表格中的元素都換成字串，並把其中的逗號刪除\n",
    "    df = df.astype(str)\n",
    "    df = df.apply(lambda s: s.str.replace(',', ''))\n",
    "    \n",
    "   # 將「證券代號」的欄位改名成「stock_id」\n",
    "    df = df.rename(columns={'證券代號':'stock_id'})\n",
    "    #設定date欄位\n",
    "    df['date'] = pd.to_datetime(date)\n",
    "    # 將 「stock_id」與「date」設定成index \n",
    "    df = df.set_index(['stock_id','date'])\n",
    "    \n",
    "    # 保留證券名稱,將所有的表格元素都轉換成數字，error='coerce'的意思是說，假如無法轉成數字，則用 NaN 取代\n",
    "    df =pd.concat([df.iloc[:,:1],df.iloc[:,1:].apply(lambda s:pd.to_numeric(s, errors='coerce'))],axis=1)\n",
    "    \n",
    "    # 刪除不必要的欄位\n",
    "    df = df[df.columns[df.isnull().all() == False]]\n",
    "    \n",
    "    #新增欄位     \n",
    "    df=df.loc[:,[\"證券名稱\",'成交股數','成交金額','開盤價','收盤價','最高價','最低價']]\n",
    "    \n",
    "    #上櫃爬蟲，將 date 變成字串 舉例：'1071012' \n",
    "    Y=str(int(date.strftime('%Y'))-1911)\n",
    "\n",
    "    datestr = Y+'/'+date.strftime('%m')+'/'+date.strftime('%d')\n",
    "    link = 'http://www.tpex.org.tw/web/stock/aftertrading/daily_close_quotes/stk_quote_download.php?l=zh-tw&d='+datestr+'&s=0,asc,0'\n",
    "    r = requests.get(link)\n",
    "\n",
    "    lines = r.text.replace('\\r', '').split('\\n')\n",
    "    df2 = pd.read_csv(StringIO(\"\\n\".join(lines[3:])), header=None)\n",
    "    \n",
    "    #設定欄名\n",
    "    df2.columns = list(map(lambda l: l.replace(' ',''), lines[2].split(',')))\n",
    "    \n",
    "    #資料處理\n",
    "    df2 = df2.apply(lambda s: s.str.replace(',', '')).apply(lambda s: s.str.replace('+', ''))\n",
    "    df2 = df2.rename(columns={'代號':'舊證券代號',\"名稱\":\"證券名稱\",\"收盤\":\"收盤價\",\"漲跌\":\"漲跌價\",\"開盤\":\"開盤價\",\n",
    "                        \"最高\":\"最高價\",\"最低\":\"最低價\",'成交金額(元)':'成交金額'})\n",
    "    df2['stock_id']=df2['舊證券代號']\n",
    "    df2=pd.concat([df2.iloc[:,:1].apply(lambda s:pd.to_numeric(s,errors='coerce')),df2.iloc[:,1:]],axis=1)\n",
    "    df2= df2[df2['舊證券代號']<9999]\n",
    "    df2['date'] = pd.to_datetime(date)\n",
    "    df2 = df2.set_index(['stock_id','date'])\n",
    "    df2=df2.drop(['舊證券代號'],axis=1)\n",
    "    df2 =pd.concat([df2.iloc[:,:1],df2.iloc[:,1:].apply(lambda s:pd.to_numeric(s, errors='coerce'))],axis=1)\n",
    "\n",
    "    df2=df2.loc[:,[\"證券名稱\",'成交股數','成交金額','開盤價','收盤價','最高價','最低價']]\n",
    "    \n",
    "    #上市與上櫃合體\n",
    "    df3=pd.concat([df,df2],axis=0)\n",
    "    df3 = df3.rename(columns={'證券名稱':'stock_name',\"成交股數\":\"turnover_vol\",\n",
    "                              \"成交金額\":\"turnover_price\",\"開盤價\":\"open_price\",\n",
    "                              \"收盤價\":\"close_price\",\"最高價\":\"high_price\",\n",
    "                              \"最低價\":\"low_price\"})\n",
    "    df3.iloc[:,3:]=df3.iloc[:,3:].apply(lambda s:pd.to_numeric(s,errors='coerce'))\n",
    "    \n",
    "    df3=df3.where(pd.notnull(df3),None)\n",
    "    df3=df3.reset_index()\n",
    "    return df3\n",
    "\n",
    "#輸入日期\n",
    "import datetime\n",
    "df=crawl_stock_price_tw(datetime.datetime(2010,12,10))\n",
    "\n",
    "\n",
    "#執行主程式\n",
    "D=CrawlerProcess(crawl_stock_price_tw,StockPriceTW,'date_range')\n",
    "print(D)\n",
    "D.auto_update_crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.specified_date_crawl('2020-03-31','2020-03-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  主程式\n",
    "\n",
    "## 月營收"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_month(date):\n",
    "    if date.month == 12:\n",
    "        url_date = datetime.date(date.year, 11, 1)\n",
    "    elif date.month > 1:\n",
    "        url_date = datetime.date(date.year, ((date.month % 12) - 1), 1)\n",
    "    else:\n",
    "        url_date = datetime.date(date.year - 1, 12, 1)\n",
    "\n",
    "    return url_date  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#定義月報爬蟲的function\n",
    "def crawl_monthly_revenue_tw(date):\n",
    "    url_date = last_month(date)\n",
    "    data = []\n",
    "    for i in ['sii', 'otc', 'rotc']:  # ,'otc','rotc'\n",
    "\n",
    "        url = 'https://mops.twse.com.tw/nas/t21/' + i + '/t21sc03_' + str(url_date.year - 1911) + '_' + str(\n",
    "            url_date.month) + '.html'\n",
    "        print(url)\n",
    "\n",
    "        # 偽瀏覽器\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "                          ' Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "        # 下載該年月的網站，並用pandas轉換成 dataframe\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers)\n",
    "            r.encoding = 'big5'\n",
    "            html_df = pd.read_html(StringIO(r.text))\n",
    "            # 處理一下資料\n",
    "            if html_df[0].shape[0] > 500:\n",
    "                df = html_df[0].copy()\n",
    "            else:\n",
    "                df = pd.concat([df for df in html_df if df.shape[1] <= 11 and df.shape[1] > 5])\n",
    "\n",
    "            if 'levels' in dir(df.columns):\n",
    "                df.columns = df.columns.get_level_values(1)\n",
    "            else:\n",
    "                df = df[list(range(0, 10))]\n",
    "                column_index = df.index[(df[0] == '公司代號')][0]\n",
    "                df.columns = df.iloc[column_index]\n",
    "\n",
    "            df['當月營收'] = pd.to_numeric(df['當月營收'], 'coerce')\n",
    "            df = df[~df['當月營收'].isnull()]\n",
    "            df = df[df['公司代號'] != '合計']\n",
    "\n",
    "            df['date'] = datetime.date(date.year, date.month, 10)\n",
    "\n",
    "            df = df.rename(columns={'公司代號': 'stock_id'})\n",
    "            df = df.set_index(['stock_id', 'date'])\n",
    "\n",
    "            data.append(df)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('**WARRN: Pandas cannot find any table in the HTML file')\n",
    "            return None\n",
    "\n",
    "    df = pd.concat(data)\n",
    "    if '備註' not in df.columns:\n",
    "        df['備註'] = None\n",
    "    df.iloc[:, 1:-1] = df.iloc[:, 1:-1].apply(lambda s: pd.to_numeric(s, errors='coerce'))\n",
    "    df = df[df['公司名稱'] != '總計']\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    df = df.rename(columns={'公司名稱': \"stock_name\", \"當月營收\": \"this_month_rev\",\n",
    "                            '上月營收': \"last_month_rev\", \"去年當月營收\": \"last_year_rev\",\n",
    "                            '上月比較增減(%)': \"cp_last_month_rev\", \"去年同月增減(%)\": \"cp_last_year_rev\",\n",
    "                            '當月累計營收': \"cm_this_month_rev\", \"去年累計營收\": \"cm_last_month_rev\",\n",
    "                            '前期比較增減(%)': \"cp_cm_rev\", \"備註\": \"note\",\n",
    "                            })\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "# a=crawl_monthly_revenue_tw(datetime.date(2001,8,10))\n",
    "# a\n",
    "#執行主程式\n",
    "M=CrawlerProcess(crawl_monthly_revenue_tw  ,MonthlyRevenueTW,'month_range')\n",
    "print(M)\n",
    "M.auto_update_crawl()\n",
    "# M.specified_date_crawl('2001-07-10','2001-08-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日期控制測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#日期控制\n",
    "import datetime\n",
    "connect_info = 'mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8'.format(\"root\",\"benbilly3@\",\"localhost\",3306,\"finlab_django\")\n",
    "engine = create_engine(connect_info)\n",
    "\n",
    "def date_control(model_name,last_day='Now'):   \n",
    "    try:\n",
    "        if last_day=='Now':\n",
    "            recent=datetime.datetime.now()\n",
    "        else:   \n",
    "            recent= datetime.datetime.strptime(last_day, \"%Y-%m-%d\")\n",
    "        end= table_latest_date(engine, model_name._meta.db_table)\n",
    "        if (recent-end).days>=0:\n",
    "            dateList = [(recent - datetime.timedelta(days=x)) for x in range((recent-end).days,-1,-1)]\n",
    "        else:\n",
    "            print(f\"The table_latest_date > your setting date,please modify your setting date >{last_day} .\")\n",
    "            return None\n",
    "    except ValueError :\n",
    "        print('Error:last_day form is %Y-%m-%d,please modify. ')\n",
    "        return None\n",
    "    return dateList\n",
    "\n",
    "date_control(StockPriceTW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_control(StockPriceTW,'2008-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specified_date_crawl(start_date:str,end_date:str):\n",
    "    \n",
    "    start_date= datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date= datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    try:\n",
    "        if (start_date-end_date).days <= 0:\n",
    "            dateList = date_range(start_date, end_date)\n",
    "        else:\n",
    "            print(f\"The start_date > your end_date,please modify your start_date <={end_date} .\")\n",
    "            return None\n",
    "    except ValueError :\n",
    "        print('Error:last_day form is %Y-%m-%d,please modify. ')\n",
    "        return None       \n",
    "    return dateList\n",
    "\n",
    "\n",
    "specified_date_crawl('2020-01-01','2020-01-05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.rrule import rrule, DAILY, MONTHLY\n",
    "\n",
    "\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    return [dt.date() for dt in rrule(DAILY, dtstart=start_date, until=end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range(datetime.datetime(2010,12,10), datetime.datetime(2010,12,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specified_date_crawl(start_date: str, end_date: str, range_date):\n",
    "\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    if range_date == 'date_range':        \n",
    "        try:\n",
    "            if (start_date - end_date).days <= 0:\n",
    "                date_list = date_range(start_date, end_date)\n",
    "                return date_list\n",
    "            else:\n",
    "                print(f\"The start_date > your end_date,please modify your start_date <={end_date} .\")\n",
    "\n",
    "        except ValueError:\n",
    "            print('Error:last_day form is %Y-%m-%d,please modify. ')\n",
    "            return None\n",
    "\n",
    "    elif range_date == 'month_range':\n",
    "        try:\n",
    "            if (start_date - end_date).days <= 0:\n",
    "                date_list = month_range(start_date, end_date)\n",
    "                date_list.append(end_date)\n",
    "                return date_list\n",
    "            else:\n",
    "                print(f\"The start_date > your end_date,please modify your start_date <={end_date} .\")\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('Error:last_day form is %Y-%m-%d,please modify. ')        \n",
    "\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "specified_date_crawl('2020-3-10','2020-04-09','month_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent = datetime.datetime.now()\n",
    "month_num = (recent - datetime.datetime(2020,1,1)).days\n",
    "month_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end= datetime.datetime.strptime(\"2019-9-12\", \"%Y-%m-%d\")\n",
    "dateList = [(end + datetime.timedelta(days=50))]\n",
    "dateList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
